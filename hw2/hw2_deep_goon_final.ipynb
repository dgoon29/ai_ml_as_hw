{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgoon29/ai_ml_as_hw/blob/main/hw2/hw2_deep_goon_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2zjX2ylYTS1"
      },
      "source": [
        "# Homework 2: Analyzing Titanic Dataset\n",
        "\n",
        "\n",
        "### Deep Goon\n",
        "\n",
        "\n",
        "**source:** https://www.kaggle.com/c/titanic/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqF0XyQbY2aW"
      },
      "source": [
        "### **Step 0:** Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "VbQ9jX6DPS_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5009ca1c-9328-416b-ead2-ebba8f6c7745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.3/spark-3.2.3-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.2.3-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "09edilH6UeAb"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.3/spark-3.2.3-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.2.3-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.3-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "0KvtnoGwVjjf"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')\n",
        "\n",
        "# # d('/content/drive/My Drive/Colab Notebooks/Spark ML Notebooks/My Work/Homework/Homework 2/titanic_train.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09jbLUd3W4hS"
      },
      "source": [
        "### **Step 1:** Load Titanic Dataset from local folder\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bH5iqNTNWYX0"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "CCdqpBpTWkrR"
      },
      "outputs": [],
      "source": [
        "dataset = spark.read.csv('titanic_train.csv', inferSchema=True, header=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYfO7wmuXstM"
      },
      "source": [
        "### **Step 2:** Familiarize yourself with the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgTHJ55mZOe9"
      },
      "source": [
        "#### i) Print the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYdaqOasWuzh",
        "outputId": "34df351d-6108-4081-eb42-f307166145d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- PassengerId: integer (nullable = true)\n",
            " |-- Survived: integer (nullable = true)\n",
            " |-- Pclass: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- SibSp: integer (nullable = true)\n",
            " |-- Parch: integer (nullable = true)\n",
            " |-- Ticket: string (nullable = true)\n",
            " |-- Fare: double (nullable = true)\n",
            " |-- Cabin: string (nullable = true)\n",
            " |-- Embarked: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dataset.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNtarPMlZaf7"
      },
      "source": [
        "#### ii) Print first 10 rows of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R04YZ8VpZT8o",
        "outputId": "0811055c-873d-47a5-faca-a5120f7d021f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
            "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
            "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
            "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
            "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
            "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
            "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
            "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
            "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
            "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dataset.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwK8clrFiDRl"
      },
      "source": [
        "#### iii) Summary statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhF8kp7WZiYE",
        "outputId": "6402b762-1443-4dc8-f659-362c0ef868a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
            "|summary|      PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n",
            "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
            "|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n",
            "|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                null|  null| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| null|    null|\n",
            "| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                null|  null|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| null|    null|\n",
            "|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n",
            "|    25%|              223|                  0|                 2|                null|  null|              20.0|                 0|                  0|           19996.0|           7.8958| null|    null|\n",
            "|    50%|              446|                  0|                 3|                null|  null|              28.0|                 0|                  0|          236171.0|          14.4542| null|    null|\n",
            "|    75%|              669|                  1|                 3|                null|  null|              38.0|                 1|                  0|          347743.0|             31.0| null|    null|\n",
            "|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n",
            "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dataset.summary().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqNpuPHubz8V",
        "outputId": "66762013-e1e7-4edc-f4c7-a39e17793c0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "|          0|       0|     0|   0|  0|177|    0|    0|     0|   0|  687|       2|\n",
            "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col, sum\n",
        "\n",
        "null_counts = dataset.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in dataset.columns])\n",
        "null_counts.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### iv) Count of 10 most frequent values"
      ],
      "metadata": {
        "id": "jkmTZjosVgZM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w5R_tzTaKg8",
        "outputId": "209f37d7-14e1-40c3-f2ff-f24bbf698d04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|   Sex|count|\n",
            "+------+-----+\n",
            "|  male|  577|\n",
            "|female|  314|\n",
            "+------+-----+\n",
            "\n",
            "+--------+-----+\n",
            "|Embarked|count|\n",
            "+--------+-----+\n",
            "|       S|  644|\n",
            "|       C|  168|\n",
            "|       Q|   77|\n",
            "|    null|    2|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "dataset.groupBy(\"Sex\").count().orderBy(col(\"count\").desc()).show(10)\n",
        "dataset.groupBy(\"Embarked\").count().orderBy(col(\"count\").desc()).show(10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctzZwDM5dnQK",
        "outputId": "f988d9ef-bfec-4183-82e3-4b6d53f9c526"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "891"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ],
      "source": [
        "dataset.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### v) Feature Selection\n",
        "\n",
        "####**Answer to v)** I might drop the cabin column as itâ€™s mostly empty (687 Nulls out of 891 total observations). For missing Age values, I will fill them with the average age."
      ],
      "metadata": {
        "id": "PRSOQUTdin8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 3:** Feature Engineering"
      ],
      "metadata": {
        "id": "asA2r5XnlQH6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "Op8vK0-bfnlG"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "feature_columns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
        "target_column = 'Survived'\n",
        "\n",
        "df = dataset.select(*feature_columns, target_column)\n",
        "\n",
        "for column in ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Survived']:\n",
        "    df = df.withColumn(column, col(column).cast('double'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "wQx56sYjiKD2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dace9fd2-f2eb-4be7-c074-40d73ba0ec81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+----+-----+-----+-------+--------+--------+\n",
            "|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Survived|\n",
            "+------+------+----+-----+-----+-------+--------+--------+\n",
            "|   3.0|  male|22.0|  1.0|  0.0|   7.25|       S|     0.0|\n",
            "|   1.0|female|38.0|  1.0|  0.0|71.2833|       C|     1.0|\n",
            "|   3.0|female|26.0|  0.0|  0.0|  7.925|       S|     1.0|\n",
            "|   1.0|female|35.0|  1.0|  0.0|   53.1|       S|     1.0|\n",
            "|   3.0|  male|35.0|  0.0|  0.0|   8.05|       S|     0.0|\n",
            "|   3.0|  male|null|  0.0|  0.0| 8.4583|       Q|     0.0|\n",
            "|   1.0|  male|54.0|  0.0|  0.0|51.8625|       S|     0.0|\n",
            "|   3.0|  male| 2.0|  3.0|  1.0| 21.075|       S|     0.0|\n",
            "|   3.0|female|27.0|  0.0|  2.0|11.1333|       S|     1.0|\n",
            "|   2.0|female|14.0|  1.0|  0.0|30.0708|       C|     1.0|\n",
            "+------+------+----+-----+-----+-------+--------+--------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, Pclass: string, Sex: string, Age: string, SibSp: string, Parch: string, Fare: string, Embarked: string, Survived: string]"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "df.show(10)\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "0wH2jWiSiKG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ed3d474-9d42-44dd-a40b-fc09a7b639c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "| Age|AgeNA|\n",
            "+----+-----+\n",
            "|22.0|    0|\n",
            "|38.0|    0|\n",
            "|26.0|    0|\n",
            "|35.0|    0|\n",
            "|35.0|    0|\n",
            "|null|    1|\n",
            "|54.0|    0|\n",
            "| 2.0|    0|\n",
            "|27.0|    0|\n",
            "|14.0|    0|\n",
            "+----+-----+\n",
            "only showing top 10 rows\n",
            "\n",
            "+-----------------+-----+\n",
            "|              Age|AgeNA|\n",
            "+-----------------+-----+\n",
            "|             22.0|    0|\n",
            "|             38.0|    0|\n",
            "|             26.0|    0|\n",
            "|             35.0|    0|\n",
            "|             35.0|    0|\n",
            "|29.69911764705882|    1|\n",
            "|             54.0|    0|\n",
            "|              2.0|    0|\n",
            "|             27.0|    0|\n",
            "|             14.0|    0|\n",
            "+-----------------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql.functions import when, mean\n",
        "\n",
        "mean_age = df.select(mean('Age')).collect()[0][0]\n",
        "\n",
        "df_2 = dataset.select(*feature_columns, target_column)\n",
        "df = df_2.withColumn('AgeNA', when(col('Age').isNull(), 1).otherwise(0))\n",
        "df.select(\"Age\", \"AgeNA\").show(10)\n",
        "df = df.na.fill({'Age': mean_age})\n",
        "df.select(\"Age\", \"AgeNA\").show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "rRrdyNhhiKLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e35bae3-bc71-4a6b-c7e9-be109d533935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+------+------------------+------------------+-------------------+-----------------+--------+-------------------+-------------------+\n",
            "|summary|            Pclass|   Sex|               Age|             SibSp|              Parch|             Fare|Embarked|           Survived|              AgeNA|\n",
            "+-------+------------------+------+------------------+------------------+-------------------+-----------------+--------+-------------------+-------------------+\n",
            "|  count|               891|   891|               891|               891|                891|              891|     889|                891|                891|\n",
            "|   mean| 2.308641975308642|  null|29.699117647058763|0.5230078563411896|0.38159371492704824| 32.2042079685746|    null| 0.3838383838383838|0.19865319865319866|\n",
            "| stddev|0.8360712409770491|  null|13.002015226002891|1.1027434322934315| 0.8060572211299488|49.69342859718089|    null|0.48659245426485753|0.39921043398804806|\n",
            "|    min|                 1|female|              0.42|                 0|                  0|              0.0|       C|                  0|                  0|\n",
            "|    25%|                 2|  null|              22.0|                 0|                  0|           7.8958|    null|                  0|                  0|\n",
            "|    50%|                 3|  null| 29.69911764705882|                 0|                  0|          14.4542|    null|                  0|                  0|\n",
            "|    75%|                 3|  null|              35.0|                 1|                  0|             31.0|    null|                  1|                  0|\n",
            "|    max|                 3|  male|              80.0|                 8|                  6|         512.3292|       S|                  1|                  1|\n",
            "+-------+------------------+------+------------------+------------------+-------------------+-----------------+--------+-------------------+-------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.summary().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TAVTWpLiKO2",
        "outputId": "ab38c994-8e27-4425-90e9-af8cc5e77ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+---+-----+-----+----+--------+--------+-----+\n",
            "|Pclass|Sex|Age|SibSp|Parch|Fare|Embarked|Survived|AgeNA|\n",
            "+------+---+---+-----+-----+----+--------+--------+-----+\n",
            "|     0|  0|  0|    0|    0|   0|       2|       0|    0|\n",
            "+------+---+---+-----+-----+----+--------+--------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "null_counts_2 = df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns])\n",
        "null_counts_2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 4:** Prepping for pipeline"
      ],
      "metadata": {
        "id": "u-nAYoOsl-rG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "C_OskLQOiKRb"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "\n",
        "sex_indexer = StringIndexer(inputCol=\"Sex\", outputCol=\"Sex_ix\", handleInvalid=\"keep\")\n",
        "sex_encoder = OneHotEncoder(inputCol=\"Sex_ix\", outputCol=\"Sex_Vec\")\n",
        "\n",
        "embarked_indexer = StringIndexer(inputCol=\"Embarked\", outputCol=\"Embarked_ix\", handleInvalid=\"keep\")\n",
        "embarked_encoder = OneHotEncoder(inputCol=\"Embarked_ix\", outputCol=\"Embarked_Vec\")\n",
        "\n",
        "indexed_cols = ['Pclass', 'Sex_Vec', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_Vec']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 5:** Feature Assembling"
      ],
      "metadata": {
        "id": "Mak5rg8XmKy1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "Td6VS9iViKUR"
      },
      "outputs": [],
      "source": [
        "va = VectorAssembler(inputCols=indexed_cols , outputCol=\"features\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 6:** Building Model"
      ],
      "metadata": {
        "id": "o45Pt5jnmPPn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "3a8VAVg_iKWd"
      },
      "outputs": [],
      "source": [
        "# lr = LogisticRegression(labelCol='Survived', featuresCol=\"features\", maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
        "# lr = LogisticRegression(labelCol='Survived', featuresCol=\"features\", maxIter=20, regParam=0.1, elasticNetParam=0.5)\n",
        "lr = LogisticRegression(labelCol='Survived', featuresCol=\"features\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 7:** Building Pipeline"
      ],
      "metadata": {
        "id": "8MfgZD8SmUg3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "c1iJU-2LiKZP"
      },
      "outputs": [],
      "source": [
        "steps = [sex_indexer, sex_encoder, embarked_indexer, embarked_encoder, va, lr]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "KteHaPyhiKbo"
      },
      "outputs": [],
      "source": [
        "pl = Pipeline(stages=steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 8:** Spliting Data to fit and evaluate model"
      ],
      "metadata": {
        "id": "XWM63YIVmZVY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VmJsL7kIQqH",
        "outputId": "8d8a88ed-8427-436f-bfb5-255ba909599c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "659\n",
            "232\n"
          ]
        }
      ],
      "source": [
        "train_df, test_df = df.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "print(train_df.count())\n",
        "print(test_df.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 9:** Fitting the model and performing predictions"
      ],
      "metadata": {
        "id": "VYaLxJw1mhLw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "-baY_hcXiKeF"
      },
      "outputs": [],
      "source": [
        "plmodel = pl.fit(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "D-KQUh4PiKjI"
      },
      "outputs": [],
      "source": [
        "predictions = plmodel.transform(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH_Q4tC4iKlk",
        "outputId": "95106020-aa37-4240-c6d2-c5b3e4f6880d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.9811139833129975,-1.4334509732767153,1.4334509732777023,-0.036646044009181415,-0.48121362032778575,-0.08530258294337861,0.0013164855171218506,-17.60729379461287,-17.017832859130557,-17.436663429920383]\n",
            "20.8285849410488\n"
          ]
        }
      ],
      "source": [
        "trained_lr_model  = plmodel.stages[-1]\n",
        "print(str(trained_lr_model.coefficients))\n",
        "print(str(trained_lr_model.intercept))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 10:** Printing result and reporting AUC"
      ],
      "metadata": {
        "id": "d5PbTK2XmsVy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6ff1fl8iKwR",
        "outputId": "a1d2cf02-2d2d-4f95-add9-60ddf5fd580c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------+----------+\n",
            "|            features|Survived|prediction|\n",
            "+--------------------+--------+----------+\n",
            "|[1.0,0.0,1.0,15.0...|       1|       1.0|\n",
            "|[1.0,0.0,1.0,17.0...|       1|       1.0|\n",
            "|[1.0,0.0,1.0,18.0...|       1|       1.0|\n",
            "|[1.0,0.0,1.0,18.0...|       1|       1.0|\n",
            "|[1.0,0.0,1.0,19.0...|       1|       1.0|\n",
            "+--------------------+--------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictions.select(\"features\", \"Survived\", \"prediction\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aNjce1CiKqe",
        "outputId": "0fde850c-8472-4a2a-a7b2-23d4dcbab9e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|                 FPR|  TPR|\n",
            "+--------------------+-----+\n",
            "|                 0.0|  0.0|\n",
            "|                 0.0|0.004|\n",
            "|                 0.0|0.008|\n",
            "|                 0.0|0.012|\n",
            "|                 0.0|0.016|\n",
            "|                 0.0| 0.02|\n",
            "|                 0.0|0.024|\n",
            "|                 0.0|0.028|\n",
            "|                 0.0|0.032|\n",
            "|                 0.0|0.036|\n",
            "|                 0.0| 0.04|\n",
            "|                 0.0|0.044|\n",
            "|0.002444987775061...|0.044|\n",
            "|0.002444987775061...|0.048|\n",
            "|0.002444987775061...|0.052|\n",
            "|0.002444987775061...|0.056|\n",
            "|0.002444987775061...| 0.06|\n",
            "|0.002444987775061...|0.064|\n",
            "|0.002444987775061...|0.068|\n",
            "|0.002444987775061...|0.072|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "0.8540244498777505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/spark-3.2.3-bin-hadoop2.7/python/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "trainingSummary = plmodel.stages[-1].summary\n",
        "trainingSummary.roc.show()\n",
        "\n",
        "auc = trainingSummary.areaUnderROC\n",
        "print(auc)\n",
        "\n",
        "\n",
        "### Question - how does this find the AUC on testing?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2TPXgxjodoSnmgzaPYUZf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}